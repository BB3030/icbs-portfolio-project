{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "The original data set [https://archive.ics.uci.edu/dataset/728/toxicity-2] has ~1200 features and only ~170 rows. It has no missing values and doesn't need any initial cleaning.\n",
    "\n",
    "However to be able to build a meaningful model with so few rows we need to reduce the feature set to 4 features. \n",
    "\n",
    "The code in this notebook achieves this by:\n",
    "\n",
    "- using 2 different feature reduction methods from the  ```klearn.feature_selection``` module\n",
    "    - Recursive Feature Elimination (RFE) model  \n",
    "    - SelectKBest \n",
    "- chooses only those features selected by both methods\n",
    "\n",
    "---\n",
    "\n",
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#string constants - centralise to avoid later 'finger trouble'\n",
    "data_folder = \"../data/\"    #relative folder path to the notebooks folder\n",
    "raw_data    = f\"{data_folder}original-data.csv\"\n",
    "final_data  = f\"{data_folder}final-data.csv\"\n",
    "\n",
    "class_column = \"Class\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATS3v</th>\n",
       "      <th>nHBint10</th>\n",
       "      <th>MATS3s</th>\n",
       "      <th>MATS3p</th>\n",
       "      <th>nHBDon_Lipinski</th>\n",
       "      <th>minHBint8</th>\n",
       "      <th>MATS3e</th>\n",
       "      <th>MATS3c</th>\n",
       "      <th>minHBint2</th>\n",
       "      <th>MATS3m</th>\n",
       "      <th>...</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>ETA_EtaP_L</th>\n",
       "      <th>ETA_EtaP_F</th>\n",
       "      <th>ETA_EtaP_B</th>\n",
       "      <th>nT5Ring</th>\n",
       "      <th>SHdNH</th>\n",
       "      <th>ETA_dEpsilon_C</th>\n",
       "      <th>MDEO-22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0908</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0436</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>1.5488</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0868</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>-0.0410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>-0.0316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>...</td>\n",
       "      <td>28.2185</td>\n",
       "      <td>8.8660</td>\n",
       "      <td>19.3525</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>1.3718</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0810</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>-0.0765</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.1791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1064</td>\n",
       "      <td>5.2267</td>\n",
       "      <td>27.8796</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>1.4395</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1004</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0251</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>-0.0894</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0747</td>\n",
       "      <td>-0.1151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>...</td>\n",
       "      <td>32.5232</td>\n",
       "      <td>7.7896</td>\n",
       "      <td>24.7336</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>1.4654</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1010</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>-0.0353</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0638</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0726</td>\n",
       "      <td>12.3240</td>\n",
       "      <td>19.7486</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>1.4495</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1071</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MATS3v  nHBint10  MATS3s  MATS3p  nHBDon_Lipinski  minHBint8  MATS3e  \\\n",
       "0  0.0908         0  0.0075  0.0173                0        0.0 -0.0436   \n",
       "1  0.0213         0  0.1144 -0.0410                0        0.0  0.1231   \n",
       "2  0.0018         0 -0.0156 -0.0765                2        0.0 -0.1138   \n",
       "3 -0.0251         0 -0.0064 -0.0894                3        0.0 -0.0747   \n",
       "4  0.0135         0  0.0424 -0.0353                0        0.0 -0.0638   \n",
       "\n",
       "   MATS3c  minHBint2  MATS3m  ...   WTPT-3   WTPT-4   WTPT-5  ETA_EtaP_L  \\\n",
       "0  0.0409        0.0  0.1368  ...   0.0000   0.0000   0.0000      0.1780   \n",
       "1 -0.0316        0.0  0.1318  ...  28.2185   8.8660  19.3525      0.1739   \n",
       "2 -0.1791        0.0  0.0615  ...  33.1064   5.2267  27.8796      0.1688   \n",
       "3 -0.1151        0.0  0.0361  ...  32.5232   7.7896  24.7336      0.1702   \n",
       "4  0.0307        0.0  0.0306  ...  32.0726  12.3240  19.7486      0.1789   \n",
       "\n",
       "   ETA_EtaP_F  ETA_EtaP_B  nT5Ring  SHdNH  ETA_dEpsilon_C  MDEO-22  \n",
       "0      1.5488      0.0088        0    0.0         -0.0868     0.00  \n",
       "1      1.3718      0.0048        2    0.0         -0.0810     0.25  \n",
       "2      1.4395      0.0116        2    0.0         -0.1004     0.00  \n",
       "3      1.4654      0.0133        2    0.0         -0.1010     0.00  \n",
       "4      1.4495      0.0120        2    0.0         -0.1071     0.00  \n",
       "\n",
       "[5 rows x 1203 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV dataset into a pandas DataFrame\n",
    "data = pd.read_csv(raw_data)\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "# convert y variable to be a numeric value with 1=Toxic and 2=NotToxic\n",
    "mapping = {\"NonToxic\":0, \"Toxic\":1}\n",
    "y = data[class_column].map(mapping)\n",
    "\n",
    "X = data.drop(class_column, axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feature selection\n",
    "\n",
    "Uses two different methods to reduce a dataset to a desired number of features (n)\n",
    "\n",
    "- ```RFE``` with Random Forest - similar to the original paper\n",
    "- ```SelectKBest``` a method that uses statistical test of significance which is model agnostic\n",
    "\n",
    "Compare the two lists of features and keep only the features that appear in both lists.\n",
    "\n",
    "Iteratively, look for common features starting with a very highly aggressive reduction (i.e. low n) and increasing n until we have a meet the desired number of common features (4)\n",
    "\n",
    "Finally,\n",
    "create final csv of data with only these features\n",
    "\n",
    "\\* _the \"hope\" is that using two very different techniques the final feature set leads to models which are more generalisable_\n",
    "\n",
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReduceFeatures(X: pd.DataFrame, \n",
    "                   y: pd.Series, \n",
    "                   n:int) -> dict:\n",
    "    \"\"\"\n",
    "    ReduceFeatures produces a dictionary of method-> feature list mappings\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): INput Variables\n",
    "        y (pd.Series):    response variables\n",
    "        n (int):          number of features to reduce to\n",
    "\n",
    "    Returns:\n",
    "        dict: _description_\n",
    "    \"\"\"    \n",
    "\n",
    "    # placeholder for features results\n",
    "    top_features = {}\n",
    "\n",
    "    # 1) RFE using Random Forest ------------------------------------------------------------------------------------------------------\n",
    "    # Initialize the RFE object with the KNN model and the desired number of features to keep\n",
    "    rfe = RFE(RandomForestClassifier(random_state=666), n_features_to_select=n)  \n",
    "\n",
    "    # Fit the RFE to the data\n",
    "    rfe.fit(X, y)\n",
    "\n",
    "    # Get the selected features\n",
    "    selected_features = X.columns[rfe.support_].to_list()\n",
    "    top_features[\"RFE: Random Forest\"] = selected_features\n",
    "    \n",
    "    # 2) SelectKBest ---------------------------------------------------------------------------------------------\n",
    "    # Initialize the SelectKBest feature selector\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=n)  \n",
    "\n",
    "    # Fit the feature selector to the data\n",
    "    X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "    # Get the selected feature indices\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "    # Get the selected feature names\n",
    "    selected_features = X.columns[selected_feature_indices].to_list()\n",
    "    top_features[\"SelectKBest\"] = selected_features\n",
    "\n",
    "    return top_features\n",
    "\n",
    "# _________________________________________________________________________________________________________________________________________\n",
    "def FindCommon(commonfeatures: dict) -> list:\n",
    "    \"\"\"\n",
    "    FindCommon: compares all lists in the dictionary and returns a list of those items found only in each\n",
    "\n",
    "    Args:\n",
    "        features (dict): a list of features for each method attempted (2 only in the first draft)\n",
    "\n",
    "    Note: \n",
    "        the code is setup for a future case where we could compare more than 2 methods (only if I have time)\n",
    "    \"\"\"   \n",
    "    feature_counts = {}\n",
    "    for key, features in commonfeatures.items():\n",
    "        for f in features:\n",
    "            if f in feature_counts.keys():\n",
    "                feature_counts[f]+=1\n",
    "            else:\n",
    "                feature_counts[f]=1\n",
    "\n",
    "    #finally use pandas to get list of features that exist only in all 3 sets\n",
    "    number_feature_sets = len(commonfeatures.keys())\n",
    "    df_feature_Counts = pd.DataFrame(list(feature_counts.items()),columns=['features', 'counts'])\n",
    "    final_features = df_feature_Counts[df_feature_Counts['counts']==number_feature_sets] \n",
    "\n",
    "    return final_features.features.to_list()\n",
    "\n",
    "#Temp code - to help saving intermediate file as it can take a while to build the intermediate datasets\n",
    "# _________________________________________________________________________________________________________________________________________\n",
    "\n",
    "#code to backup top_features\n",
    "def backup(data: object, path: str):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# _________________________________________________________________________________________________________________________________________\n",
    "#code to read it back later\n",
    "def restore(path: str) -> object:\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main reduction algorithm\n",
    "\n",
    "Iteratively call reduction technique until we have the desired number of \"important\" features\n",
    "\n",
    " - 4 in the first draft\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_feature_number = 4 # particular low number becuase of the small number of records\n",
    "\n",
    "Current_features = 0        # progress - how many common features we have found so far\n",
    "Cached_featuresets = {}     # results from each iteration of the reduction functions\n",
    "                            #  - key:   n used in iteration\n",
    "                            #  - value: list of common features\n",
    "\n",
    "n = 10  # Current \"bucket\" size for feature search for each iteration\n",
    "while Current_features < desired_feature_number:\n",
    "    #reduce features using different methods\n",
    "    features_found = ReduceFeatures(X, y, n)\n",
    "    backup(features_found,f\"{data_folder}features-found-{n}.pkl\")\n",
    "    \n",
    "    #Find common\n",
    "    common_features = FindCommon(features_found)\n",
    "    Cached_featuresets[n] = common_features\n",
    "    Current_features = len(Cached_featuresets[n])\n",
    "\n",
    "    if Current_features < desired_feature_number:\n",
    "        n+=10\n",
    "\n",
    "# now we're out of the loop \n",
    "#   - inspect the last cached entry and see if it has over-shot\n",
    "#   - if we have too many thanuse the set just below the threshold from the previous iteration\n",
    "#       - with such a small data set it is better to have too few than too many fetures\n",
    "#       - [its all guess work at thi stage right ;-)]\n",
    "if len(Cached_featuresets[n])==desired_feature_number:\n",
    "    final_features = Cached_featuresets[n]\n",
    "else:\n",
    "    final_features = Cached_featuresets[n-10]\n",
    "    for f in Cached_featuresets[n]:\n",
    "        if not f in final_features:\n",
    "            final_features.append(f)\n",
    "        if len(final_features)==desired_feature_number:\n",
    "            break;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction algorithm results:\n",
      "\n",
      "\tDimension:\n",
      "\t\t10\n",
      "\tCommon Featuress:\n",
      "\t\tSpDiam_Dt\n",
      "\t\tMDEC-23\n",
      "\t\tSpMin3_Bhi\n",
      "\t\tATSC1v\n",
      "\n",
      "\tDimension:\n",
      "\t\t20\n",
      "\tCommon Featuress:\n",
      "\t\tMDEC-23\n",
      "\t\tSpDiam_Dt\n",
      "\t\tSpMin3_Bhi\n",
      "\t\tATSC1v\n",
      "\t\tSpMAD_Dt\n",
      "Final Choice:\n",
      "\t[SpDiam_Dt, MDEC-23, SpMin3_Bhi, ATSC1v]\n"
     ]
    }
   ],
   "source": [
    "print(\"Reduction algorithm results:\")\n",
    "\n",
    "for k,v in Cached_featuresets.items():\n",
    "    print(f\"\\n\\tDimension:\\n\\t\\t{k}\\n\\tCommon Featuress:\")\n",
    "    print('\\t\\t' + '\\n\\t\\t'.join(v))\n",
    "\n",
    "print(f\"Final Choice:\\n\\t[{', '.join(final_features)}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Data output\n",
    "\n",
    "Create csv files of final dataset with reduced number of features used by the model notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create final data to be saved as csv file - note we're retaining the un-scaled data\n",
    "X_Final = X[final_features].copy()\n",
    "X_Final[\"Toxic\"] = y\n",
    "\n",
    "X_Final.to_csv(final_data, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
