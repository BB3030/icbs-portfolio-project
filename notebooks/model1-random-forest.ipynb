{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Toxicity Classification using Random Forest\n",
    "\n",
    "Code to train a simple Random Forest model to predict toxicity\n",
    "\n",
    "- use k-fold crossvalidation with grid-search to find best performing model on the training data\n",
    "    - k==5\n",
    "    - scoring metric = recall\n",
    "- validate final model against a \"hold-out\" dataset\n",
    "- fit final model using the full dataset and best hyper-parameters\n",
    "- save trained model as pickle file (in case it is selected as the final model)\n",
    "\n",
    "_**note on scoring metric:**_ choosing 'recall' as performance metric due to the potentail harm that can be caused be mis-labelling a toxic drug as harmless. In a real research scenario an in-silico model such as this would only be used to screen out obviously toxic drugs from a large list of candidates at an early stage and there must be more robust experimentally reliable tests performed downstream before the drug gets anywhere near a human being. \n",
    "\n",
    "---\n",
    "\n",
    "## Imports and Constants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#string constants - centralise to avoid later 'finger trouble'\n",
    "data_folder = \"../data/\"                     #relative folder path to the notebooks folder\n",
    "data  = f\"{data_folder}final-data.csv\"       # in the real world datasets would be registered in a system like W&B to protect them from modification\n",
    "model_folder = \"../models/\"\n",
    "\n",
    "class_column = \"Toxic\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Prep\n",
    "\n",
    "- Split dataset into input variables (X) and response variables (y)\n",
    "- Create a hold-out set\n",
    "    - use stratification to ensure proportion of toxic vs non-toxic is retained in the hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "toxicity_data = pd.read_csv(data)\n",
    "\n",
    "#seperate in to X, y\n",
    "X = toxicity_data.drop(class_column, axis=1)\n",
    "y = toxicity_data[class_column]\n",
    "\n",
    "#create a hold-out dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model training and hyper-parameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=666)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 15, 25],\n",
    "    'min_samples_split': [5, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Create a k-fold cross-validation splitter\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "\n",
    "# Perform hyperparameter search with k-fold cross-validation\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=k_fold, scoring='recall')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Display the best hyperparameters and the corresponding mean cross-validated score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hold out' test set results\n",
      "\tRecall:\t\t0.91\n",
      "\tAccuracy:\t0.97\n",
      "Full dataset results\n",
      "\tRecall:\t\t0.95\n",
      "\tAccuracy:\t0.98\n"
     ]
    }
   ],
   "source": [
    "# test set validation\n",
    "\n",
    "#define classifier\n",
    "final_rf_classifier = RandomForestClassifier(random_state=666, \n",
    "                                            n_estimators        =grid_search.best_params_[\"n_estimators\"],\n",
    "                                            max_depth           =grid_search.best_params_[\"max_depth\"],\n",
    "                                            min_samples_split   =grid_search.best_params_[\"min_samples_split\"],\n",
    "                                            min_samples_leaf    =grid_search.best_params_[\"min_samples_leaf\"],\n",
    "                                            max_features        =grid_search.best_params_[\"max_features\"])\n",
    "#fit model with best hyper-parameters\n",
    "final_rf_classifier.fit(X,y)\n",
    "\n",
    "#make predictions\n",
    "y_test_pred = final_rf_classifier.predict(X_test)\n",
    "\n",
    "#compare with actuals\n",
    "original_toxic = np.count_nonzero(y_test)\n",
    "correctly_predicted_toxic = np.count_nonzero(y_test & y_test_pred)\n",
    "\n",
    "recall = correctly_predicted_toxic/original_toxic\n",
    "accuracy = np.count_nonzero(y_test==y_test_pred) / len(y_test_pred)\n",
    "\n",
    "print(\"'Hold out' test set results\")\n",
    "print(f\"\\tRecall:\\t\\t{recall:.2f}\")\n",
    "print(f\"\\tAccuracy:\\t{accuracy:.2f}\")\n",
    "\n",
    "# Full data set ------------------------\n",
    "#make predictions\n",
    "y_pred = final_rf_classifier.predict(X)\n",
    "\n",
    "#compare with actuals\n",
    "original_toxic = np.count_nonzero(y)\n",
    "correctly_predicted_toxic = np.count_nonzero(y & y_pred)\n",
    "\n",
    "recall = correctly_predicted_toxic/original_toxic\n",
    "accuracy = np.count_nonzero(y==y_pred) / len(y_pred)\n",
    "\n",
    "print(\"Full dataset results\")\n",
    "print(f\"\\tRecall:\\t\\t{recall:.2f}\")\n",
    "print(f\"\\tAccuracy:\\t{accuracy:.2f}\")\n",
    "\n",
    "with open(f'{model_folder}model1-rf-trained.pkl', 'wb') as f:\n",
    "        pickle.dump(final_rf_classifier, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
